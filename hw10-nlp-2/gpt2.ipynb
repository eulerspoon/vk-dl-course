{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oq43jDtsYeVZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "3tZCg_JfYl3_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, model_name: str = \"gpt2\"):\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "\n",
        "    def greedy_sampling(self, logits: torch.Tensor) -> int:\n",
        "        return torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    def random_sampling(self, logits: torch.Tensor) -> int:\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        return torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "    def _beam_search_generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        max_length: int,\n",
        "        num_beams: int\n",
        "    ) -> str:\n",
        "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        beam_scores = torch.zeros(num_beams, dtype=torch.float)\n",
        "        beam_sequences = input_ids.repeat(num_beams, 1)\n",
        "\n",
        "        for step in range(max_length - len(input_ids[0])):\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(beam_sequences)\n",
        "                next_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "            next_token_probs = F.softmax(next_token_logits, dim=-1)\n",
        "\n",
        "            vocab_size = next_token_probs.size(-1)\n",
        "            expanded_scores = beam_scores.unsqueeze(1).expand(-1, vocab_size)\n",
        "            token_scores = expanded_scores + torch.log(next_token_probs)\n",
        "\n",
        "            flat_scores = token_scores.view(-1)\n",
        "            top_scores, top_indices = torch.topk(flat_scores, num_beams)\n",
        "\n",
        "            beam_indices = top_indices // vocab_size\n",
        "            token_indices = top_indices % vocab_size\n",
        "\n",
        "            new_sequences = []\n",
        "            for i in range(num_beams):\n",
        "                beam_idx = beam_indices[i]\n",
        "                token_idx = token_indices[i]\n",
        "                new_sequence = torch.cat([\n",
        "                    beam_sequences[beam_idx],\n",
        "                    token_idx.unsqueeze(0)\n",
        "                ])\n",
        "                new_sequences.append(new_sequence)\n",
        "\n",
        "            beam_sequences = torch.stack(new_sequences)\n",
        "            beam_scores = top_scores\n",
        "\n",
        "            if torch.all(beam_sequences[:, -1] == self.tokenizer.eos_token_id):\n",
        "                break\n",
        "\n",
        "        best_beam_idx = torch.argmax(beam_scores)\n",
        "        best_sequence = beam_sequences[best_beam_idx]\n",
        "\n",
        "        return self.tokenizer.decode(best_sequence, skip_special_tokens=True)\n",
        "\n",
        "    def apply_temperature(self, logits: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:\n",
        "        return logits / temperature\n",
        "\n",
        "    def _apply_top_p(self, logits: torch.Tensor, top_p: float = 1.0) -> torch.Tensor:\n",
        "        if top_p >= 1.0:\n",
        "            return logits\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        sorted_probs, sorted_indices = torch.sort(probs, descending=True, dim=-1)\n",
        "\n",
        "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "        mask = cumulative_probs > top_p\n",
        "\n",
        "        mask[:, 1:] = mask[:, :-1].clone()\n",
        "        mask[:, 0] = False\n",
        "\n",
        "        scatter_mask = torch.zeros_like(mask)\n",
        "        scatter_mask.scatter_(-1, sorted_indices, mask)\n",
        "        filtered_logits = logits.masked_fill(scatter_mask, float('-inf'))\n",
        "\n",
        "        return filtered_logits\n",
        "\n",
        "    def _apply_top_k(self, logits: torch.Tensor, top_k: float = None) -> torch.Tensor:\n",
        "        if top_k is None or top_k <= 0 or top_k > self.vocab_size:\n",
        "            return logits\n",
        "\n",
        "        values, _ = torch.topk(logits, top_k)\n",
        "        min_value = values[:, -1] if logits.dim() > 1 else values[-1]\n",
        "\n",
        "        mask = logits < min_value.unsqueeze(-1) if logits.dim() > 1 else logits < min_value\n",
        "\n",
        "        filtered_logits = logits.masked_fill(mask, float('-inf'))\n",
        "        return filtered_logits\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        max_length: int = 50,\n",
        "        strategy: str = \"greedy\",\n",
        "        temperature: float = 1.0,\n",
        "        top_k: int = 0,\n",
        "        top_p: float = 1.0,\n",
        "        num_beams: int = 3\n",
        "    ) -> str:\n",
        "\n",
        "        if strategy == \"beam_search\":\n",
        "            return self._beam_search_generate(prompt, max_length, num_beams)\n",
        "\n",
        "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        generated = input_ids.clone()\n",
        "\n",
        "        for _ in range(max_length - len(input_ids[0])):\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(generated)\n",
        "                next_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "            if temperature != 1.0:\n",
        "                next_token_logits = self.apply_temperature(next_token_logits, temperature)\n",
        "\n",
        "            if top_k > 0:\n",
        "                next_token_logits = self._apply_top_k(next_token_logits, top_k)\n",
        "\n",
        "            if top_p < 1.0:\n",
        "                next_token_logits = self._apply_top_p(next_token_logits, top_p)\n",
        "\n",
        "            if strategy == \"greedy\":\n",
        "                next_token_id = self.greedy_sampling(next_token_logits)\n",
        "            elif strategy == \"random\":\n",
        "                next_token_id = self.random_sampling(next_token_logits)\n",
        "\n",
        "            next_token = torch.tensor([[next_token_id]], dtype=torch.long)\n",
        "            generated = torch.cat([generated, next_token], dim=1)\n",
        "\n",
        "            if next_token_id == self.tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "        return self.tokenizer.decode(generated[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "tQ7Lr7cKYveR"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "2Pe6JktdcT6t"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    'To be or not to',\n",
        "    'The funny name for my cat is',\n",
        "    'The capital of Greece is'\n",
        "]"
      ],
      "metadata": {
        "id": "Og410SKFeVkO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"greedy\", max_length=35)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mqXU-FedDL",
        "outputId": "1ebde8cd-eb94-4e85-8e32-93f2e5b876c1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be, the only thing that matters is that you're a good person.\n",
            "\n",
            "I'm not saying that you should be a good person. I \n",
            "\n",
            "The funny name for my cat is \"The Cat.\"\n",
            "\n",
            "I'm not sure if I'm going to be able to keep my cat, but I'm sure I'll \n",
            "\n",
            "The capital of Greece is Athens, and the capital of the country is Athens. The capital of Greece is Athens.\n",
            "\n",
            "The capital of Greece is Athens. The capital of \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", temperature=1.0, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLtLFvV-ftO-",
        "outputId": "a57181c3-713b-4e81-c2c1-1040bac4e18c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be, the most striking signs of symptomatology are those phenomena which \\iikal \\u28s\\. \\ \n",
            "\n",
            "The funny name for my cat is Terra (oh and for the cats, like the hat! Who knew you'd donate my work through this blog!). \n",
            "\n",
            "The capital of Greece is Athens – another city of rampantly poor inhabitants, who live as refugees and find comfort from the Greek dependents, often inter \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", temperature=0.5, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTaWwA4AfwFY",
        "outputId": "e6e34265-c02e-4e73-c166-286af5c13af9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be, the most important thing is to have a good relationship with the person you are with.\n",
            "\n",
            "As a general rule \n",
            "\n",
            "The funny name for my cat is \"Mongoose.\"\n",
            "\n",
            "I've been a fan of the show since it first came out and I'm \n",
            "\n",
            "The capital of Greece is Athens. The country's economy is booming, and the country's exports are growing.\n",
            "\n",
            "But the country's economy is \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", temperature=2.0, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_i-dtLjgATU",
        "outputId": "56968efa-b08a-41d8-92c5-486514318811"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to self meared from trunk lows src Biplay reparl 1899 Associate Rails Deputy, missions mur Collot?Enlarge decree Eugene Fish \n",
            "\n",
            "The funny name for my cat is Darth GambleLock vibucci remix Dolphan desauriad… Curryzilla upload replace companion masks added laser fencing cul \n",
            "\n",
            "The capital of Greece is game sublime cash dunk MichelleTurBelow Stories UN Shutdown role src   denotes pride alarms capable McGee erection funnel gadget reception allev lady Gets \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", top_k=10, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OJvSHXpgG3M",
        "outputId": "00cb0efe-babd-4246-86e8-3d9dc2c508c9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be. The only way to know is to go to the store, buy some candy and then go back to the car.\" \n",
            "\n",
            "The funny name for my cat is \"Darling,\" which means \"little girl,\" so I guess he doesn't know what that means?\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "The capital of Greece is Athens. It is an island of over a thousand islands.\n",
            "\n",
            "In the early days of the Greek Empire, Athens had \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", top_p=0.9, max_length=60)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctNDiPGRgjfA",
        "outputId": "7de3ec20-b8f1-4943-ecda-550a707c60b6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be an early blazer, you'll need to hide it from around the house as well as with your car. Make sure to keep your UAV as close as you can to the wall and wall of the house so your guests can see your UAV when you come out \n",
            "\n",
            "The funny name for my cat is The Cats. Actually, while she is adorable, she has no traits of hers; she spends most of her time staring at her people. This is because her personality doesn't seem to have much to do with nature itself; her broad shoulders, a special tan belly \n",
            "\n",
            "The capital of Greece is Athens, but it took five years for it to see its bailout payments cut, and now is starting to see major cuts. Not long ago, an IMF report found that, despite a radical collapse, GDP grew by $1.8tn in 2014. New direct deposits from \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"beam_search\", num_beams=3, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTPIDRZ1gpNw",
        "outputId": "3ba28809-2085-410e-f7cd-ef53f47f08bb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be, the only thing that matters is that you're a good person.\n",
            "\n",
            "I'm not saying that you should be \n",
            "\n",
            "The funny name for my cat is \"The Cat.\"\n",
            "\n",
            "I'm not sure if I'm going to be able to keep my cat, but \n",
            "\n",
            "The capital of Greece is Athens, and the capital of the country is Athens. The capital of Greece is Athens.\n",
            "\n",
            "The capital of Greece is \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    result = model.generate(prompt, strategy=\"random\", temperature=0.7, top_p=0.9, max_length=30)\n",
        "    print(result, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX8f32Mdng_j",
        "outputId": "01103b8e-c6c6-451f-89cf-32886aed20e0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be a real person, I don't know. I'm not interested in it. I'm not interested in being a crazy \n",
            "\n",
            "The funny name for my cat is \"S-bot.\" It's a \"bot\" that's created to make it look like a person's hand \n",
            "\n",
            "The capital of Greece is the country with the most mobile-phone use, and the number of mobile phones used per capita is expected to increase by more \n",
            "\n"
          ]
        }
      ]
    }
  ]
}